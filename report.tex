\documentclass[12pt, a4paper]{article} % Assuming 'article' class, adjust if needed

% --- Preamble (Include necessary packages) ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[a4paper, margin=2.5cm]{geometry} % Adjust margins as needed
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{float} % For [H] placement if needed later
\usepackage{csquotes} % Required by biblatex when using babel
\usepackage[backend=bibtex, style=numeric]{biblatex} % changed backend to bibtex for simpler compile (or keep biber if you prefer)
\addbibresource{references.bib} % use plain relative filename; ensure references.bib is in the same folder as report.tex

% --- ADD: Allow underscores in normal text to avoid "Missing $ inserted" errors ---
\usepackage{underscore}

% --- Add these to your Preamble ---
\usepackage{xcolor}
\usepackage{listings}

% Define a custom style for Python code
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{purple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Report_Delaplace_20245433},
    pdfpagemode=FullScreen
}

% --- Custom Title Page Info ---
\newcommand{\coursename}{Module: Algorithms and Combinatorial Thinking}
\newcommand{\academicyear}{2025-2026}
\newcommand{\instructorname}{Dr. Franck Delaplace}
\newcommand{\groupmembers}{Christos Christophoros Mitsakopoulos}

\begin{document}

% --- Title Page ---
\begin{titlepage}
    \centering % Center everything on the title page

    % --- Logos ---
    \begin{minipage}[t]{0.1\textwidth}
        \centering
        \includegraphics[height=2.5cm]{logo_blue.png} % Adjust height as needed
    \end{minipage}
    \hfill % Pushes logos to opposite sides
    \begin{minipage}[t]{0.25\textwidth}
        \centering
        \raisebox{0.7cm}{\includegraphics[height=1.5cm]{logo_purple.png}} % Adjust height as needed
    \end{minipage}

    
    {\Huge \bfseries Metaheuristic approach to the Hamiltonian Path \par}


    \vspace{1cm} % Space between logos and title
    \begin{minipage}[t]{1\textwidth}
        \centering
        \includegraphics[width=12cm]{title_page.png}
        \captionof{figure}{\textit{Visualised with Pyvis, depicts the correct Hamiltonian path through the artificially generated, 50 node graph.}}
    \end{minipage}
    \vspace{0.3cm}

    % --- Course/Module Info ---
    {\Large \coursename \space \academicyear \par}

    \vspace{1cm} % Space before author/group info

    % --- Author/Group Info ---
    {\large \textbf{Written by:} \par}
    \vspace{0.2cm}
    \begin{Large}
    \groupmembers
    \end{Large}
    \par

    \vspace{0.5cm} % Space before instructor info

    % --- Instructor Info ---
    {\large \textbf{Supervised by:} \space \instructorname \par}


    \vfill % Pushes the date to the bottom

    % --- Date ---
    {\large \today \par} % Automatically inserts the compilation date
    % Or use: {\large October 27, 2025 \par} for a fixed date

    %\vspace*{1cm} % Add some space at the bottom

\end{titlepage}

% --- Table of Contents ---
\tableofcontents
\newpage

% --- Introduction ---
\section{Formal Definition and Introduction}

To start with, the Hamiltonian Path problem asks if a graph $G=(V, E)$ contains a path that visits every vertex / node $v \in V$ exactly once. 

Given that the Hamiltonian Path problem is NP-Complete, as the number of vertices of the vertex set $n = |V|$ increases, the computational complexity required to solve the problem via brute force grows factorially ($O(n!)$). Consequently, exact algorithms become computationally intractable for large $n$, necessitating the use of metaheuristics -- like the ones tested in this report. For this exact reason no evaluation of a brute force approach has been considered in the experiments of this report, as the computational and time complexity required is too high to practically implement. This report evaluates three metaheuristic approaches: \textit{Simulated Annealing}, \textit{Tabu Search}, and a \textit{Genetic Algorithm}.

In the context of bioinformatics, specifically \textit{de novo} genome assembly, this problem is interesting. Arranging DNA reads in an acyclic graph can be modelled as finding a Hamiltonian path that maximises read overlap to create a contiguous sequence. Since this is a bioinformatics course, a genetic algorithm appropriated from the course material (much like all other algorithms implemented) was tested to match the theme of genome assembly heuristics.

\bigskip

Find all relevant results / as well as reproduce the experiment using the \texttt{main.py} at the following address: \url{https://github.com/cmitsakopoulos/Delaplace_coursework}. The Python script automates all tests demonstrated in this report and moreover, accepts user arguments through the command line interface; intended for tweaking parameters regarding base graph generation.

\begin{lstlisting}[language=Python, caption=Usage scenario where the number of nodes for the problem graph are set to 50, with the probability of any two nodes having a connecting edge is 0.15. (This was ran in a Python environment -- ensure you install the dependencies listed in the annex.)]
(project) chrismitsacopoulos@192 Delaplace_coursework % python3 main.py --nodes 50 --prob 0.15
\end{lstlisting}

\section{Test Environment -- Random Generation of the Problem: Erdős-Rényi Random Graph}

To benchmark the metaheuristic algorithms, an Erdős-Rényi (ER) $G(n,p)$ model was used. In which: 
\begin{itemize}
    \item $n$: The number of vertices in the graph.
    \item $p$: The probability that an edge exists between any two distinct vertices.
\end{itemize}

A larger parameter $p$ will by effect increase the likelihood of finding a Hamiltonian Path, given that the probability of any two nodes having a connecting edge is larger. This was evident when first trying out the \texttt{main.py} Python script, where preliminary tests with a  $p$ of $\approx0.3$ and $n=50$ showed that a Hamiltonian Path was indeed mathematically possible to find; so much so that all algorithms would converge to a zero cost solution (no broken edges).

\begin{lstlisting}[language=Python, caption=Small snippet of code in which NetworkX in Python can generate an ER graph of chosen parameters, identify that the default options are intended for a "challenging" benchmark for the algorithms. Hardcoding the seed was not a deliberate analytical choice, just to ensure reproducibility of the graph itself -- the algorithms are stochastic too...)
# n default = 50, p default = 0.1, seed hardcoded to 42
g_exp = nx.erdos_renyi_graph(n=num_nodes, p=prob, seed=SEED)
\end{lstlisting}

\bigskip

To ensure significance of the results, each metaheuristic algorithm was executed for $N=30$ runs. Relying on the Central Limit Theorem, the sampling distribution of the mean approximates a normal distribution as $N \geq 30$, even if the underlying population distribution is non-Gaussian. While increasing $N$ reduces the Standard Error of the Mean (SEM), the precision improves only with the square root of $N$ (i.e., $\text{SEM} = \sigma / \sqrt{N}$). 

\section{Metaheuristics: Mode of Action and Objective Functions}

The objective function of Simulated Annealing (SA) seeks to minimise the cost of "broken edges" or gaps while searching for $G$ (where $G$ = zero broken edges). 

To ensure significance of the results, each metaheuristic algorithm was executed for $N=30$ runs. Relying on the Central Limit Theorem, the sampling distribution of the mean approximates a normal distribution as $N \geq 30$, even if the underlying population distribution is non-Gaussian. While increasing $N$ reduces the Standard Error of the Mean (SEM), the precision improves only with the square root of $N$ (i.e., $\text{SEM} = \sigma / \sqrt{N}$). 

\end{document}