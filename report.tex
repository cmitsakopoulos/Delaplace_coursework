\documentclass[12pt, a4paper]{article} % Assuming 'article' class, adjust if needed

% --- Preamble (Include necessary packages) ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[a4paper, margin=2.5cm]{geometry} % Adjust margins as needed
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{float} % For [H] placement if needed later
\usepackage{csquotes} % Required by biblatex when using babel
\usepackage[backend=bibtex, style=numeric]{biblatex} % changed backend to bibtex for simpler compile (or keep biber if you prefer)
\addbibresource{references.bib} % use plain relative filename; ensure references.bib is in the same folder as report.tex

% --- ADD: Allow underscores in normal text to avoid "Missing $ inserted" errors ---
\usepackage{underscore}

% --- Add these to your Preamble ---
\usepackage{xcolor}
\usepackage{listings}

% Define a custom style for Python code
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{purple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Report_Delaplace_20245433},
    pdfpagemode=FullScreen
}

% --- Custom Title Page Info ---
\newcommand{\coursename}{Module: Algorithms and Combinatorial Thinking}
\newcommand{\academicyear}{2025-2026}
\newcommand{\instructorname}{Dr. Franck Delaplace}
\newcommand{\groupmembers}{Christos Christophoros Mitsakopoulos}

\begin{document}

% --- Title Page ---
\begin{titlepage}
    \centering % Center everything on the title page

    % --- Logos ---
    \begin{minipage}[t]{0.1\textwidth}
        \centering
        \includegraphics[height=2.5cm]{logo_blue.png} % Adjust height as needed
    \end{minipage}
    \hfill % Pushes logos to opposite sides
    \begin{minipage}[t]{0.25\textwidth}
        \centering
        \raisebox{0.7cm}{\includegraphics[height=1.5cm]{logo_purple.png}} % Adjust height as needed
    \end{minipage}

    
    {\Huge \bfseries Metaheuristic approach to the Hamiltonian Path \par}


    \vspace{1cm} % Space between logos and title
    \begin{minipage}[t]{1\textwidth}
        \centering
        \includegraphics[width=12cm]{title_page.png}
        \captionof{figure}{\textit{Visualised with Pyvis, depicts the incomplete solution -- Hamiltonian path, which the GA found using the 2-OPT (inversion) operator in the Erdős-Rényi random graph. Broken edges are depicted in red.}}
    \end{minipage}
    \vspace{0.3cm}

    % --- Course/Module Info ---
    {\Large \coursename \space \academicyear \par}

    \vspace{1cm} % Space before author/group info

    % --- Author/Group Info ---
    {\large \textbf{Written by:} \par}
    \vspace{0.2cm}
    \begin{Large}
    \groupmembers
    \end{Large}
    \par

    \vspace{0.5cm} % Space before instructor info

    % --- Instructor Info ---
    {\large \textbf{Supervised by:} \space \instructorname \par}


    \vfill % Pushes the date to the bottom

    % --- Date ---
    {\large \today \par} % Automatically inserts the compilation date
    % Or use: {\large October 27, 2025 \par} for a fixed date

    %\vspace*{1cm} % Add some space at the bottom

\end{titlepage}

% --- Table of Contents ---
\tableofcontents
\newpage

% --- Introduction ---
\section{Formal Definition and Introduction}

To start with, the Hamiltonian Path problem asks if a graph $G=(V, E)$ contains a path that visits every vertex / node $v \in V$ exactly once. 

\bigskip

Given that the Hamiltonian Path problem is NP-Complete, as the number of vertices of the vertex set $n = |V|$ increases, the computational complexity required to solve the problem via brute force grows factorially ($O(n!)$). Consequently, exact algorithms become computationally intractable for large $n$, necessitating the use of metaheuristics -- like the ones tested in this report. For this exact reason no evaluation of a brute force approach has been considered in the experiments of this report, as the computational and time complexity required is too high to practically implement. This report evaluates three metaheuristic approaches: \textit{Simulated Annealing}, \textit{Tabu Search}, and a \textit{Genetic Algorithm}.

\bigskip

In the context of bioinformatics, specifically \textit{de novo} genome assembly, this problem is interesting. Arranging DNA reads in an acyclic graph can be modelled as finding a Hamiltonian path that maximises read overlap to create a contiguous sequence. Since this is a bioinformatics course, a genetic algorithm appropriated from the course material (much like all other algorithms implemented) was tested to match the theme of genome assembly heuristics.

\bigskip

Find all relevant results / as well as reproduce the experiment using the \texttt{main.py} at the following address: \url{https://github.com/cmitsakopoulos/Delaplace_coursework}. The Python script automates all tests demonstrated in this report and moreover, accepts user arguments through the command line interface; intended for tweaking parameters regarding base graph generation.

\begin{lstlisting}[language=Python, caption=\textit{Usage scenario where the number of nodes for the problem graph are set to 50, with the probability of any two nodes having a connecting edge is 0.15. (This was ran in a Python environment -- ensure you install the dependencies listed in the annex.)}]
(project) chrismitsacopoulos@192 Delaplace_coursework % python3 main.py --nodes 50 --prob 0.15
\end{lstlisting}

\section{Random Generation of the Problem: Erdős-Rényi Random Graph}

To benchmark the metaheuristic algorithms, an Erdős-Rényi (ER) $G(n,p)$ model was used. In which: 
\begin{itemize}
    \item $n$: The number of vertices in the graph.
    \item $p$: The probability that an edge exists between any two distinct vertices.
\end{itemize}

A larger parameter $p$ will by effect increase the likelihood of finding a Hamiltonian Path, given that the probability of any two nodes having a connecting edge is larger. This was evident when first trying out the \texttt{main.py} Python script, where preliminary tests with a  $p$ of $\approx0.3$ and $n=50$ showed that a Hamiltonian Path was indeed mathematically possible to find; so much so that all algorithms would converge to a zero cost solution (no broken edges).

\begin{lstlisting}[language=Python, caption=\textit{Small snippet of code in which NetworkX in Python can generate an ER graph of chosen parameters, identify that the default options are intended for a "challenging" benchmark for the algorithms. Hardcoding the seed was not a deliberate analytical choice, just to ensure reproducibility of the graph itself -- the algorithms are stochastic too...}]
# n default = 50, p default = 0.1, seed hardcoded to 42
g_exp = nx.erdos_renyi_graph(n=num_nodes, p=prob, seed=SEED)
\end{lstlisting}

\section{Test Environment: Experimental Choices and Reasoning}

To ensure significance of the results, each metaheuristic algorithm was executed for $N=30$ runs. Relying on the Central Limit Theorem, the sampling distribution of the mean approximates a normal distribution as $N \geq 30$, even if the underlying population distribution is non-Gaussian. While increasing $N$ reduces the Standard Error of the Mean (SEM), the precision improves only with the square root of $N$ (i.e., $\text{SEM} = \sigma / \sqrt{N}$). 

\bigskip

Additionally, in order to observe the impact on phase transition across all metaheuristics tested, the Komlós & Szemerédi theorem/threshold was used to compute the theoretical--$p$--limit of the problem graph, specifically using the following equation: 

\begin{equation}
    p_{\text{limit}} = \frac{\ln(n) + \ln(\ln(n))}{n}
\end{equation}


While $p < p_{\text{limit}}$, the probability of a Hamiltonian path existing approaches zero; thus any algorithm claiming a valid solution is likely "hallucinating'', being overconfident (due to verification errors), or has encountered a statistical anomaly (highly unlikely in my testing case). Conversely, for $p > p_{\text{limit}}$, a path almost surely exists; consequently, if an algorithm fails to converge to a zero-cost solution in this region (zero broken edges), it shows that the algorithm is underperforming rather than the problem being impossible.

\bigskip

Another important consideration, was to examine the impact of switching from a \text{"Swap"} operator to an \textbf{"Inversion" (2-OPT) operator} between testing cases. This was not only tested in the case of GA, to demonstrate how it can be a positive addition on an already accurate algorithm. However, it was also tested in the case of SA and GA to show that the impact of this change is not algorithm-specific; this should become evident when looking at the \textbf{"Phase Transition"} experiment of this report, where the 2-OPT operator was used instead of the Swap operator.

\section{Metaheuristic Algorithms: Mode of Action and Code Snippets}

\subsection{Objective Function}
All algorithms used aim to identify a permutation $S$ of vertices that minimises the number of broken edges in the path. For a graph $G=(V,E)$ and a candidate path $S = [v_1, v_2, \dots, v_n]$, the cost function $C(S)$ is defined as:

\begin{equation}
    C(S) = (n-1) - \sum_{i=1}^{n-1} \mathbb{I}((v_i, v_{i+1}) \in E)
\end{equation}
Where $\mathbb{I}$ is an indicator function that equals 1 if the edge exists and 0 otherwise. A global optimum is reached when $C(S) = 0$ -- a Hamiltonian Path.

\subsection{Simulated Annealing (SA)}

Simulated Annealing explores solutions by accepting both better or even, worse solutions, based on a probability that decreases over time (referred to as parameter $T$). This logic prevents the algorithm from arriving at a final solution, before it has found the true solution inside the solution space. The probability $P$ -- of accepting --  a new solution $S'$ with cost difference $\Delta C = C(S') - C(S)$ is governed by the Metropolis criterion (see also the Python implementation below):

\begin{equation}
    P(\text{accept}) = 
    \begin{cases} 
    1 & \text{if } \Delta C < 0 \\
    e^{-\frac{\Delta C}{T}} & \text{if } \Delta C \geq 0 
    \end{cases}
\end{equation}

\begin{lstlisting}[language=Python, caption=\textit{Metropolis Criterion: As the loop progresses, the temperature $T$ decays geometrically ($T_{k+1} = 0.985 \cdot T_k$), gradually turning the search into a simple greedy descent (hill climbing)}]
# From main.py: Calculate cost difference
delta = neighbor_cost - current_cost

# Accept if better (delta < 0) OR with probability exp(-delta/T)
if delta < 0 or random.random() < exp(-delta / temp):
    current = neighbor
    current_cost = neighbor_cost
\end{lstlisting}

\subsection{Tabu Search (TS)}
Tabu Search differs from SA by using a deterministic, memory-based approach. TS explores an immediate neighbourhood of a current solution it has found and moves to the best available neighbour (=solution), even if that neighbour is worse than the current solution.

\bigskip
To prevent cycling (revisiting the same solutions again and again), the algorithm maintains a \textit{Tabu List} -- a short-term memory that prevents recent solutions for a specific duration, called tenure.

\begin{lstlisting}[language=Python, caption=Tabu Search Memory Logic]
# From main.py: Moving to the best candidate not in the Tabu list
if cand not in tabu_list:
    current = cand
    found_move = True
    
# Update memory
tabu_list.append(current)
if len(tabu_list) > tenure:
    tabu_list.pop(0) # Remove oldest entry
\end{lstlisting}

\subsection{Genetic Algorithm (GA)}

The Genetic Algorithm attempts to mimic natural selection. Unlike SA and TS, which improve a single solution, GA evolves a population of solutions. The operator for permutation is \textit{Ordered Crossover} (OX1), which is important because standard single-point crossover would result in duplicate or missing vertices / nodes.

\bigskip
The code uses OX1 to preserve the ordering of a sub-segment from one "parent" while filling the remaining slots with genes from the second "parent".

\begin{lstlisting}[language=Python, caption=Ordered Crossover (OX1) Implementation]
# From main.py: Preserves sub-segment from parent 1
child[start:end] = p1[start:end]

# Fills remaining slots from parent 2, skipping duplicates
for i in range(size):
    if child[i] is None:
        while p2[current_p2_idx] in child:
            current_p2_idx += 1
        child[i] = p2[current_p2_idx]
\end{lstlisting}
\bigskip
Using the standard \texttt{swap} operator (exchanging two indices) disrupts the adjacency of the path significantly. In comparison, the \texttt{inversion} (2-Opt) operator reverses a segment of the path. This is mathematically better for path search problems because it preserves the internal adjacency of the reversed segment, only breaking the two edges at the endpoints of the segment. This distinction is implemented via the `op_inversion` function in `main.py` and is the primary driver for convergence in denser graphs. A graph is produced at the end during testing to demonstrate the differences of both applications. 

\begin{equation}
    \text{Swap}(S) \rightarrow \text{High disruption of edges}
\end{equation}
\begin{equation}
    \text{Inversion}(S) \rightarrow \text{Minimal disruption (2-Opt)}
\end{equation}

\section{Experiment: Comparing the Metaheuristic Algorithms}

\subsection{Batch Testing}

The experiment code in \texttt{main.py} has been hardcoded to repeat the stochastic run of each metaheuristic algorithm 30 times, with the user chosen parameters upon initialization through the command line. The results depicted in \autoref{fig:batch_results} and \autoref{fig:phase_transition}, were computed with an ER problem graph of $n=50$ and $p=0.15$.

\bigskip

Briefly, with reference to \autoref{fig:batch_results}, the lowest solution quality (highest number of broken edges) is demonstrated by SA, then TS and with the GA, being the best performer. Inversely, the highest execution time per batch run, was demonstrated by GA, followed by TS and lastly SA. These results confirm the expected correlation between computational cost and solution quality (indicating the code works as intended). SA is the fastest because it performs a single $O(1)$ evaluation per step, but its single-trajectory stochasticity struggles to escape bad solutions (local optima) in a solution landscape. TS improves solving quality by improving local search, by evaluating a neighbourhood of size $k=50$ per step ($O(k)$), which linearly increases runtime. Lastly, the GA achieves a near-optimal solution at the highest computational cost; it maintains diversity through a population-based search ($O(P \cdot N)$ per generation), allowing it to traverse the complex fitness landscape more effectively than the trajectory-based methods. 

\bigskip

Nevertheless, the results in \autoref{fig:batch_results} clearly show that all algorithms -- apart from the GA -- are greatly underperforming in this testing case. For an ER graph with $n=50$, the Komlós & Szemerédi limit is $p=0.106$, considering that the chosen -- testing -- $p=0.15$, is greater than the theoretical limit, a solution should be mathematically infeasible; albeit, difficult to obtain. 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{experiment_1_batch_results.png}
    \caption{\textit{In the box & whisker plots depicted, "Solution Quality" (Y-axis: Broken Edges) is shown on the left and "Execution Time" (Y-axis: Time(seconds)) on the right. As discussed prior, due to the low probability of edges between any two nodes, the graph is sparse and the metaheuristic algorithms -- while performing differently from one another -- are not succesful in this testing case. As such, the amount of broken edges seen between algorithms is not unlikely, and the inverse relationship between the number of broken edges and execution time is a clear demonstration of algorithmic complexity -- which leads to positive outcomes in problem solving.} }
    \label{fig:batch_results}
\end{figure}

\subsection{Phase Transition}

Briefly, with reference to \autoref{fig:phase_transition}, there appears to be overconfidence of the TS and GA algorithms, which demonstrate a non-zero level of success at a mathematically improbable rate of $p=0.1$; where $p = 0.1 < p_{\text{limit}} = 0.106$. Given that the difference between $p$ and $p_{\text{limit}}$ is $\Delta p = 0.006$, this could be believed to be a statistical anomaly that occured in this new 30-run test -- compared to the previous batch testing scenario. After introducing a new \texttt{argparse} argument to the \texttt{main.py} file to exclusively re-run the phase transition experiment, the results -- over 5 re-runs -- led to the same conclusions as in \autoref{fig:phase_transition}. One could argue that due to a \textbf{switch from the "Swap" operator to the more optimised "Inversion" (2-Opt) operator}, the GA and TS algorithms are able to find a global optimum at a mathematically improbable rate of $p=0.1$, as well as be considerably succesful at higher graph densities ($p>0.1$); all the while SA is equally performing better than before (than in \autoref{fig:batch_results}). 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{experiment_3_phase_transition.png}
    \caption{\textit{This line chart depicts the phase transition of the proposed problem Erdos-Renyi graph, at a cycling $p$ rate between 0.05 and 0.3. The theoretical limit is computed automatically based on the input problem graph, given the Komlós & Szemerédi formula. Observe overconfidence from the TS and GA algorithms, which demonstrate success at a mathematically improbable rate of $p$. The success rate of all algorithms is congruent with previous results.}}
    \label{fig:phase_transition}
\end{figure}

\section{GA: Comparing Swap Operator to 2-Opt}

Congruent with the phase transition results, it is evident that the switch from the Swap operator (\autoref{fig:batch_results}) to the Inversion (2-Opt) operator (\autoref{fig:phase_transition}), improves the performance of the GA (see \autoref{fig:optimisation_comparison_GA}). Importantly, looking at the number of broken edges at each iteration, it is clear that the 2-OPT based GA converges at a faster and smoother, or more consistent pace, than the Swap based GA. To briefly reiterate on what was said prior on the report, this phenomenon can be due to two complementary reasons:

\bigskip

Firstly, the \texttt{2-OPT} (or inversion) operator is less destructive at each iteration. It reverses a segment between indices $i$ and $j$ at each iteration, removing two edges $(v_i, v_{i+1})$ and $(v_j, v_{j+1})$, and replacing them with $(v_i, v_j)$ and $(v_{i+1}, v_{j+1})$, whilst preserving the adjacency of all nodes within the segment. As such, the 2-OPT operator enables the algorithm to make small changes which are beneficial at each iteration. Therefore, as can be seen in \autoref{fig:optimisation_comparison_GA}, the GA with the 2-OPT operator improves its global solution at each iteration, whereas the Swap operator will repeatedly plateau/stagnate due to destructive solutions between iterations. Secondly, as mentioned before, the \texttt{Swap} operator exchanges two nodes $v_i$ and $v_j$ arbitrarily, which can affect up to four edges: $(v_{i-1}, v_i), (v_i, v_{i+1}), (v_{j-1}, v_j),$ and $(v_j, v_{j+1})$. Instead of making minor improvements locally, the Swap operator will lead to the algorithm making more destructive changes at each iteration; causing the search to stagnate (maintain one solution over multiple iterations) until a more rare, but more beneficial solution is accidentally found by the destructive search.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{experiment_2_optimization_comparison.png}
    \caption{\textit{In the depicted line chart, Broken Edges (Y-axis) for which the objective function seeks to minimise (Cost) by maximising the number of edges in the path, is plotted against the number of generations -- repeated runs (X-axis). The GA with the Swap operator is shown in blue, while the GA with the Inversion (2-Opt) operator is in orange. Observe the clear disparity between the two operators, in which it's clear that the 2-OPT operator GA converges much faster to a near-global optimum (zero broken edges) than its Swap-GA counterpart.}}
    \label{fig:optimisation_comparison_GA}
\end{figure}

\section{Annex}

\begin{lstlisting}[language=Python, caption=Python 3.14.2]
import random
import time
import math
import itertools
import argparse
import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
from math import exp, log

# --- CONFIGURATION ---
SNS_THEME = "whitegrid"
SNS_CONTEXT = "paper"
SEED = 42

# Apply settings
random.seed(SEED)
np.random.seed(SEED)
sns.set_theme(style=SNS_THEME, context=SNS_CONTEXT, font_scale=1.2)

# ==========================================
# 1. CORE HELPER & FITNESS FUNCTIONS
# ==========================================

def get_initial_solution(nodes):
    """Returns a random permutation of nodes."""
    p = list(nodes).copy()
    random.shuffle(p)
    return p

def count_edges(path, graph):
    """Counts valid edges in the path for a specific graph."""
    edges = 0
    # Optimization: Iterate via index to avoid creating new lists
    for i in range(len(path) - 1):
        if graph.has_edge(path[i], path[i+1]):
            edges += 1
    return edges

def fitness_min(path, graph):
    """Minimisation: Returns number of broken edges. Target = 0."""
    target = len(path) - 1
    valid = count_edges(path, graph)
    return float(target - valid)

def fitness_max(path, graph):
    """Maximisation: Returns number of valid edges. Target = N-1."""
    return float(count_edges(path, graph))

# ==========================================
# 2. OPERATORS (THE OPTIMISATIONS)
# ==========================================

def op_swap(genome):
    """Standard Swap: Exchanges two random nodes."""
    n = len(genome)
    i, j = random.sample(range(n), 2)
    genome[i], genome[j] = genome[j], genome[i]
    return genome

def op_inversion(genome):
    """
    2-Opt Inversion: Reverses a random sub-segment.
    OPTIMIZATION: Preserves adjacency better than swap.
    """
    n = len(genome)
    i, j = sorted(random.sample(range(n), 2))
    # Reverse the segment between i and j
    genome[i:j+1] = genome[i:j+1][::-1]
    return genome

# ==========================================
# 3. METAHEURISTIC ALGORITHMS
# ==========================================

def run_simulated_annealing(graph, max_steps=3000, temp0=100.0, operator="swap"):
    """Simulated Annealing with selectable operator."""
    nodes = list(graph.nodes)
    current = get_initial_solution(nodes)
    best = current.copy()
    
    current_cost = fitness_min(current, graph)
    best_cost = current_cost
    trace = [best_cost]
    temp = temp0
    
    mutate_func = op_inversion if operator == "inversion" else op_swap
    
    for step in range(max_steps):
        if best_cost == 0: break
            
        neighbor = current.copy()
        neighbor = mutate_func(neighbor)
        
        neighbor_cost = fitness_min(neighbor, graph)
        delta = neighbor_cost - current_cost
        
        if delta < 0 or random.random() < exp(-delta / temp):
            current = neighbor
            current_cost = neighbor_cost
            if current_cost < best_cost:
                best = current.copy()
                best_cost = current_cost
        
        trace.append(best_cost)
        temp *= 0.985 
        
    return best, best_cost, trace

def run_tabu_search(graph, max_steps=1000, tenure=20, operator="swap"):
    """Tabu Search with selectable operator."""
    nodes = list(graph.nodes)
    current = get_initial_solution(nodes)
    best = current.copy()
    best_cost = fitness_min(best, graph)
    
    tabu_list = []
    trace = [best_cost]
    mutate_func = op_inversion if operator == "inversion" else op_swap
    
    for step in range(max_steps):
        if best_cost == 0: break
            
        candidates = []
        for _ in range(50):
            cand = current.copy()
            cand = mutate_func(cand)
            candidates.append(cand)
            
        candidates.sort(key=lambda p: fitness_min(p, graph))
        
        found_move = False
        for cand in candidates:
            cand_cost = fitness_min(cand, graph)
            if cand_cost < best_cost:
                current = cand
                best = cand
                best_cost = cand_cost
                found_move = True
                break
            if cand not in tabu_list:
                current = cand
                found_move = True
                break
        
        trace.append(best_cost)
        if found_move:
            tabu_list.append(current)
            if len(tabu_list) > tenure:
                tabu_list.pop(0)

    return best, best_cost, trace

def run_genetic_algorithm(graph, pop_size=200, generations=1000, cross_rate=0.8, mut_rate=0.3, operator="swap"):
    """Genetic Algorithm with selectable operator."""
    nodes = list(graph.nodes)
    target = len(nodes) - 1
    
    mutate_func = op_inversion if operator == "inversion" else op_swap

    def ordered_crossover(p1, p2):
        size = len(p1)
        start, end = sorted(random.sample(range(size), 2))
        child = [None] * size
        child[start:end] = p1[start:end]
        current_p2_idx = 0
        for i in range(size):
            if child[i] is None:
                while p2[current_p2_idx] in child:
                    current_p2_idx += 1
                child[i] = p2[current_p2_idx]
        return child

    population = [get_initial_solution(nodes) for _ in range(pop_size)]
    best_sol = None
    best_broken = float('inf')
    trace = [] 

    for gen in range(generations):
        fitnesses = [fitness_max(p, graph) for p in population]
        best_val = max(fitnesses)
        current_broken = target - best_val
        
        if current_broken < best_broken:
            best_broken = current_broken
            best_sol = population[fitnesses.index(best_val)]
        
        trace.append(best_broken)
        if current_broken == 0: break
            
        next_pop = [best_sol.copy()] 
        while len(next_pop) < pop_size:
            competitors = random.sample(population, 3)
            winner = max(competitors, key=lambda p: fitness_max(p, graph))
            next_pop.append(winner.copy())
        population = next_pop

        for i in range(1, pop_size - 1, 2):
            if random.random() < cross_rate:
                population[i] = ordered_crossover(population[i], population[i+1])
                
        for i in range(1, pop_size):
            if random.random() < mut_rate:
                population[i] = mutate_func(population[i])

    return best_sol, best_broken, trace

# ==========================================
# 4. EXPERIMENT RUNNERS
# ==========================================

def run_batch_experiments(num_nodes, prob):
    """Runs each algorithm 30 times and plots results."""
    # Baseline comparison using Standard Swap
    OPERATOR = "swap" 
    
    g_exp = nx.erdos_renyi_graph(n=num_nodes, p=prob, seed=SEED)
    
    print(f"\n--- 1. BATCH EXPERIMENT (Baseline 'Swap', N={num_nodes}, p={prob}, 30 Runs) ---")
    
    def run_batch(algo_func, name):
        scores = []
        times = []
        successes = 0
        for _ in range(30):
            start = time.time()
            _, cost, _ = algo_func(g_exp)
            dur = time.time() - start
            scores.append(cost)
            times.append(dur)
            if cost == 0: successes += 1
        
        rate = (successes/30)*100
        print(f"{name}: Mean Cost={np.mean(scores):.2f}, Success={rate:.1f}%, Mean Time={np.mean(times):.4f}s")
        return scores, times

    sa_scores, sa_times = run_batch(lambda g: run_simulated_annealing(g, max_steps=3000, operator=OPERATOR), "SA")
    tabu_scores, tabu_times = run_batch(lambda g: run_tabu_search(g, max_steps=1500, operator=OPERATOR), "Tabu")
    ga_scores, ga_times = run_batch(lambda g: run_genetic_algorithm(g, generations=1500, operator=OPERATOR), "GA")

    data = {
        'Algorithm': ['SA']*30 + ['Tabu']*30 + ['GA']*30,
        'Broken Edges': sa_scores + tabu_scores + ga_scores,
        'Time (s)': sa_times + tabu_times + ga_times
    }
    df = pd.DataFrame(data)

    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    sns.boxplot(data=df, x='Algorithm', y='Broken Edges', hue='Algorithm', 
                legend=False, ax=axes[0], palette="viridis")
    axes[0].set_title(f'Solution Quality (N={num_nodes}, Lower is Better)')
    axes[0].set_ylim(bottom=-0.5) 
    
    sns.boxplot(data=df, x='Algorithm', y='Time (s)', hue='Algorithm', 
                legend=False, ax=axes[1], palette="magma")
    axes[1].set_title(f'Execution Time (N={num_nodes})')
    axes[1].set_ylim(bottom=0)
    
    plt.tight_layout()
    plt.savefig('experiment_1_batch_results.png', dpi=300, bbox_inches='tight')
    print("Saved 'experiment_1_batch_results.png'")
    # plt.show() # Uncomment if running interactively

def run_optimization_comparison(num_nodes):
    """Compares Standard 'Swap' vs Optimized 'Inversion' (2-Opt)."""
    print(f"\n--- 2. OPTIMISATION EVALUATION (N={num_nodes}) ---")
    g_opt = nx.erdos_renyi_graph(n=num_nodes, p=0.1, seed=SEED)
    
    print("Running SA with Standard Swap...")
    _, _, trace_swap = run_simulated_annealing(g_opt, max_steps=4000, operator="swap")
    
    print("Running SA with Optimized Inversion (2-Opt)...")
    _, _, trace_inv = run_simulated_annealing(g_opt, max_steps=4000, operator="inversion")
    
    df_opt = pd.DataFrame({
        'Step': list(range(len(trace_swap))) + list(range(len(trace_inv))),
        'Broken Edges': trace_swap + trace_inv,
        'Variant': ['Standard (Swap)'] * len(trace_swap) + ['Optimized (2-Opt)'] * len(trace_inv)
    })
    
    plt.figure(figsize=(10, 6))
    sns.lineplot(data=df_opt, x='Step', y='Broken Edges', hue='Variant', linewidth=2.5)
    plt.title(f'Impact of Neighborhood Structure: Swap vs 2-Opt (N={num_nodes})')
    plt.ylabel('Broken Edges (Cost)')
    plt.xlabel('Iteration Step')
    plt.ylim(bottom=-0.5)
    
    plt.savefig('experiment_2_optimization_comparison.png', dpi=300, bbox_inches='tight')
    print("Saved 'experiment_2_optimization_comparison.png'")

def run_phase_transition(num_nodes):
    """
    Analyzes difficulty vs graph density across ALL algorithms.
    This provides a comprehensive view of algorithmic limits.
    """
    print(f"\n--- 3. PHASE TRANSITION ANALYSIS (N={num_nodes}) ---")
    # Densities to test
    densities = [0.05, 0.08, 0.1, 0.12, 0.15, 0.2, 0.25, 0.3]
    
    # Calculate Theoretical Threshold for THIS N
    # Komlós & Szemerédi theorem: p = (ln(n) + ln(ln(n))) / n
    if num_nodes > 1:
        math_threshold = (log(num_nodes) + log(log(num_nodes))) / num_nodes
        print(f"Theoretical Critical Threshold for N={num_nodes}: p ~ {math_threshold:.3f}")
    else:
        math_threshold = 0
    
    # Store results for plotting
    results = {'Density': [], 'Success Rate': [], 'Algorithm': []}
    
    # Test all algorithms to see which one handles the transition best
    algorithms = {
        'SA': lambda g: run_simulated_annealing(g, max_steps=2500, operator="inversion"),
        'Tabu': lambda g: run_tabu_search(g, max_steps=1500, operator="inversion"),
        'GA': lambda g: run_genetic_algorithm(g, generations=1000, operator="inversion")
    }

    for p in densities:
        # Create a graph for this density
        # Note: Ideally we average over multiple graphs, but for speed we use one seed per density
        # or we generate a fresh one each run. Let's stick to one graph instance per density 
        # but 10 runs per algorithm on it.
        g = nx.erdos_renyi_graph(n=num_nodes, p=p, seed=999)
        
        print(f"Testing Density p={p}...")
        
        for name, algo_func in algorithms.items():
            successes = 0
            for _ in range(10): # 10 runs per density/algorithm pair
                _, cost, _ = algo_func(g)
                if cost == 0: successes += 1
            
            rate = (successes/10)*100
            results['Density'].append(p)
            results['Success Rate'].append(rate)
            results['Algorithm'].append(name)
            
    df_phase = pd.DataFrame(results)
        
    plt.figure(figsize=(10, 6))
    sns.lineplot(data=df_phase, x='Density', y='Success Rate', hue='Algorithm', marker='o', linewidth=2)
    
    # Plot the Theoretical Line
    plt.axvline(x=math_threshold, color='r', linestyle='--', label=f'Theoretical Limit (p={math_threshold:.2f})')
    
    plt.title(f'Phase Transition: Experiment vs Theory (N={num_nodes})')
    plt.xlabel('Graph Density (p)')
    plt.ylabel('Success Rate (%)')
    plt.ylim(-5, 105)
    plt.legend()
    plt.grid(True)
    
    plt.savefig('experiment_3_phase_transition.png', dpi=300, bbox_inches='tight')
    print("Saved 'experiment_3_phase_transition.png'")

def save_best_graph_html(num_nodes, prob):
    """Runs GA once and saves the result to HTML."""
    print("\n--- 4. GENERATING VISUALISATION ---")
    try:
        from pyvis.network import Network
    except ImportError:
        print("Pyvis not installed. Skipping.")
        return

    # Use arguments, but if probability is too low, we might not find a path
    g = nx.erdos_renyi_graph(n=num_nodes, p=prob, seed=SEED)
    path, cost, _ = run_genetic_algorithm(g, generations=2000, operator="inversion")
    
    print(f"Final Path Cost: {cost}")
    
    net = Network(height="600px", width="100%", cdn_resources='remote')
    
    for n in g.nodes:
        net.add_node(int(n), label=str(n), color='#97c2fc')
        
    for u, v in g.edges:
        net.add_edge(int(u), int(v), color='#e0e0e0', width=1)
        
    for i in range(len(path) - 1):
        u, v = int(path[i]), int(path[i+1])
        if g.has_edge(u, v):
            net.add_edge(u, v, color='red', width=4)
        else:
            net.add_edge(u, v, color='red', width=4, dashes=True) 
            
    net.show("hamiltonian_path.html", notebook=False)
    print("Saved to 'hamiltonian_path.html'")

# ==========================================
# MAIN EXECUTION
# ==========================================

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Hamiltonian Path Metaheuristic Analysis")
    parser.add_argument("-N", "--nodes", type=int, default=50, help="Number of nodes in the graph (default: 50)")
    parser.add_argument("-p", "--prob", type=float, default=0.1, help="Edge creation probability (default: 0.1)")
    parser.add_argument("--mode", type=str, default="all", choices=["all", "batch", "opt", "phase", "visual"], help="Experiment mode to run individually")

    
    args = parser.parse_args()
    
    print(f"Running experiments with N={args.nodes} and p={args.prob}, Mode={args.mode}")
    
    # 1. Main Baseline (using 'Swap')
    if args.mode in ["all", "batch"]:
        run_batch_experiments(args.nodes, args.prob)
    
    # 2. The Report Recommendation (Proving 2-Opt is better)
    if args.mode in ["all", "opt"]:
        run_optimization_comparison(args.nodes)
    
    # 3. Physics/Difficulty Analysis (Runs ALL algorithms across densities)
    if args.mode in ["all", "phase"]:
        run_phase_transition(args.nodes)
    
    # 4. Visual Output
    if args.mode in ["all", "visual"]:
        save_best_graph_html(args.nodes, args.prob)
\end{lstlisting}


\end{document}